# üöÄ Guia de Atualiza√ß√£o da Edge Function - AssemblyAI

## üìã Resumo

A Edge Function `dynamic-processor` precisa ser atualizada para suportar **Speaker Diarization** usando a API nativa da **AssemblyAI**. A boa not√≠cia: **AssemblyAI j√° tem diarization integrada e √© GR√ÅTIS!**

---

## ‚úÖ O que AssemblyAI Oferece NATIVAMENTE

### 1. **Speaker Diarization (Speaker Labels)**
- ‚úÖ Identifica automaticamente diferentes speakers ("A", "B", "C", etc.)
- ‚úÖ **Gr√°tis** - inclu√≠do no plano padr√£o
- ‚úÖ Suporta de 1 a 10 speakers
- ‚úÖ Funciona com √°udio mono e est√©reo
- ‚úÖ Melhorias de 2024-2025: 10.1% mais preciso!

### 2. **Timestamps Precisos**
- ‚úÖ Timestamps em milissegundos
- ‚úÖ Start/end para cada utterance (fala)
- ‚úÖ Word-level timestamps tamb√©m dispon√≠veis

### 3. **Multichannel (√Åudio Est√©reo)**
- ‚úÖ Processa cada canal separadamente
- ‚úÖ 100% de acur√°cia (cada canal = 1 speaker)
- ‚úÖ Ideal para entrevistas gravadas com 2 microfones

---

## üîß Como Funciona a API da AssemblyAI

### Passo 1: Upload do √Åudio
```javascript
// POST https://api.assemblyai.com/v2/upload
// Headers: { 'authorization': 'YOUR_API_KEY' }
// Body: arquivo bin√°rio

// Response:
{
  "upload_url": "https://cdn.assemblyai.com/upload/ccbbbfaf-f319-4455-9556-272d48faaf7f"
}
```

### Passo 2: Criar Transcri√ß√£o com Diarization
```javascript
// POST https://api.assemblyai.com/v2/transcript
// Headers: { 'authorization': 'YOUR_API_KEY' }

// Request body:
{
  "audio_url": "https://cdn.assemblyai.com/upload/ccbbbfaf-f319-4455-9556-272d48faaf7f",
  "language_code": "pt",           // ou 'en', 'es', etc.
  "speaker_labels": true,           // ‚Üê ATIVAR DIARIZATION
  "speakers_expected": 2            // Opcional: n√∫mero de speakers esperados
}

// Response:
{
  "id": "5552830-d8b1-4e60-a2b4-bdfefb3130b3",
  "status": "queued"  // ou "processing", "completed"
}
```

### Passo 3: Polling (Verificar Status)
```javascript
// GET https://api.assemblyai.com/v2/transcript/{id}
// Headers: { 'authorization': 'YOUR_API_KEY' }

// Response quando status = "completed":
{
  "id": "5552830-d8b1-4e60-a2b4-bdfefb3130b3",
  "status": "completed",
  "text": "Hi, I'm joy. Hi, I'm sharon. Do you have kids in school?",
  "utterances": [
    {
      "speaker": "A",
      "confidence": 0.97,
      "start": 0,           // milliseconds
      "end": 1380,          // milliseconds
      "text": "Hi, I'm joy.",
      "words": [
        {
          "text": "Hi",
          "start": 0,
          "end": 210,
          "confidence": 0.99,
          "speaker": "A"
        }
      ]
    },
    {
      "speaker": "B",
      "confidence": 0.95,
      "start": 1380,
      "end": 2650,
      "text": "Hi, I'm sharon.",
      "words": [...]
    }
  ]
}
```

---

## üìù Atualiza√ß√£o da Edge Function

### C√≥digo Atual (Presumido)
```typescript
// supabase/functions/dynamic-processor/index.ts

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const ASSEMBLYAI_API_KEY = Deno.env.get('ASSEMBLYAI_API_KEY')

serve(async (req) => {
  try {
    const formData = await req.formData()
    const audioFile = formData.get('file')
    const language = formData.get('language') || 'pt'

    // 1. Upload do arquivo para AssemblyAI
    const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
      method: 'POST',
      headers: { 'authorization': ASSEMBLYAI_API_KEY },
      body: audioFile
    })

    const { upload_url } = await uploadResponse.json()

    // 2. Criar transcri√ß√£o
    const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
      method: 'POST',
      headers: {
        'authorization': ASSEMBLYAI_API_KEY,
        'content-type': 'application/json'
      },
      body: JSON.stringify({
        audio_url: upload_url,
        language_code: language
      })
    })

    const { id } = await transcriptResponse.json()

    // 3. Polling at√© completar
    let transcript
    while (true) {
      const pollingResponse = await fetch(
        `https://api.assemblyai.com/v2/transcript/${id}`,
        { headers: { 'authorization': ASSEMBLYAI_API_KEY } }
      )

      transcript = await pollingResponse.json()

      if (transcript.status === 'completed') break
      if (transcript.status === 'error') throw new Error(transcript.error)

      await new Promise(resolve => setTimeout(resolve, 3000))
    }

    return new Response(JSON.stringify({
      success: true,
      text: transcript.text
    }), {
      headers: { 'Content-Type': 'application/json' }
    })

  } catch (error) {
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
})
```

---

### C√≥digo ATUALIZADO (Com Diarization + Timestamps)

```typescript
// supabase/functions/dynamic-processor/index.ts

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"

const ASSEMBLYAI_API_KEY = Deno.env.get('ASSEMBLYAI_API_KEY')

// Mapeamento de c√≥digos de idioma
const LANGUAGE_MAP: Record<string, string> = {
  'pt': 'pt',
  'en': 'en',
  'es': 'es',
  'fr': 'fr',
  'de': 'de',
  'it': 'it'
}

serve(async (req) => {
  try {
    const formData = await req.formData()
    const audioFile = formData.get('file')
    const language = formData.get('language') || 'pt'
    const enableDiarization = formData.get('diarization') === 'true'  // ‚Üê NOVO

    console.log('Recebido:', {
      fileName: audioFile?.name,
      language,
      diarization: enableDiarization
    })

    // 1. Upload do arquivo para AssemblyAI
    const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
      method: 'POST',
      headers: { 'authorization': ASSEMBLYAI_API_KEY },
      body: audioFile
    })

    if (!uploadResponse.ok) {
      throw new Error(`Upload falhou: ${uploadResponse.statusText}`)
    }

    const { upload_url } = await uploadResponse.json()
    console.log('Upload URL:', upload_url)

    // 2. Criar transcri√ß√£o com configura√ß√µes
    const transcriptConfig: any = {
      audio_url: upload_url,
      language_code: LANGUAGE_MAP[language] || 'pt'
    }

    // ‚Üê ADICIONAR DIARIZATION SE HABILITADO
    if (enableDiarization) {
      transcriptConfig.speaker_labels = true
      // Opcional: especificar n√∫mero esperado de speakers
      // transcriptConfig.speakers_expected = 2
    }

    console.log('Config:', transcriptConfig)

    const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
      method: 'POST',
      headers: {
        'authorization': ASSEMBLYAI_API_KEY,
        'content-type': 'application/json'
      },
      body: JSON.stringify(transcriptConfig)
    })

    if (!transcriptResponse.ok) {
      throw new Error(`Transcri√ß√£o falhou: ${transcriptResponse.statusText}`)
    }

    const { id } = await transcriptResponse.json()
    console.log('Transcript ID:', id)

    // 3. Polling at√© completar (timeout de 5 minutos)
    const startTime = Date.now()
    const TIMEOUT = 5 * 60 * 1000  // 5 minutos

    let transcript
    while (true) {
      if (Date.now() - startTime > TIMEOUT) {
        throw new Error('Timeout: transcri√ß√£o demorou mais de 5 minutos')
      }

      const pollingResponse = await fetch(
        `https://api.assemblyai.com/v2/transcript/${id}`,
        { headers: { 'authorization': ASSEMBLYAI_API_KEY } }
      )

      transcript = await pollingResponse.json()
      console.log('Status:', transcript.status)

      if (transcript.status === 'completed') break
      if (transcript.status === 'error') {
        throw new Error(`Erro na transcri√ß√£o: ${transcript.error}`)
      }

      // Aguardar 3 segundos antes de verificar novamente
      await new Promise(resolve => setTimeout(resolve, 3000))
    }

    console.log('Transcri√ß√£o conclu√≠da!')

    // 4. Processar resposta
    const response: any = {
      success: true,
      text: transcript.text,
      language: transcript.language_code
    }

    // ‚Üê ADICIONAR SEGMENTS COM SPEAKERS SE DISPON√çVEL
    if (transcript.utterances && transcript.utterances.length > 0) {
      response.segments = transcript.utterances.map((utterance: any) => ({
        start: utterance.start / 1000,      // Converter ms para segundos
        end: utterance.end / 1000,          // Converter ms para segundos
        text: utterance.text,
        speaker: utterance.speaker ? `Speaker ${utterance.speaker}` : undefined,
        confidence: utterance.confidence
      }))

      console.log(`${response.segments.length} segmentos processados`)
    }

    return new Response(JSON.stringify(response), {
      headers: { 'Content-Type': 'application/json' }
    })

  } catch (error) {
    console.error('Erro:', error)

    return new Response(JSON.stringify({
      success: false,
      error: error.message || 'Erro desconhecido'
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
})
```

---

## üîë Vari√°veis de Ambiente

Certifique-se de que a Edge Function tem acesso √† chave da API:

```bash
# No dashboard do Supabase:
# Settings > Edge Functions > Secrets

ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here
```

Para obter a API Key:
1. Acesse [AssemblyAI Dashboard](https://www.assemblyai.com/app)
2. Fa√ßa login ou crie conta
3. V√° em "API Keys"
4. Copie sua chave

---

## üìä Formato da Resposta Esperado

### Sem Diarization
```json
{
  "success": true,
  "text": "Esta √© a transcri√ß√£o completa do √°udio.",
  "language": "pt"
}
```

### Com Diarization
```json
{
  "success": true,
  "text": "Ol√°, como vai? Tudo bem, obrigado!",
  "language": "pt",
  "segments": [
    {
      "start": 0.0,
      "end": 1.38,
      "text": "Ol√°, como vai?",
      "speaker": "Speaker A",
      "confidence": 0.97
    },
    {
      "start": 1.38,
      "end": 2.65,
      "text": "Tudo bem, obrigado!",
      "speaker": "Speaker B",
      "confidence": 0.95
    }
  ]
}
```

---

## üß™ Como Testar

### 1. Deploy da Edge Function
```bash
# Instalar Supabase CLI (se n√£o tiver)
npm install -g supabase

# Login
supabase login

# Linkar projeto
supabase link --project-ref YOUR_PROJECT_REF

# Deploy
supabase functions deploy dynamic-processor
```

### 2. Testar com cURL
```bash
# Sem diarization
curl -X POST https://YOUR_PROJECT.supabase.co/functions/v1/dynamic-processor \
  -H "apikey: YOUR_SUPABASE_ANON_KEY" \
  -H "Authorization: Bearer YOUR_SUPABASE_ANON_KEY" \
  -F "file=@audio.mp3" \
  -F "language=pt"

# Com diarization
curl -X POST https://YOUR_PROJECT.supabase.co/functions/v1/dynamic-processor \
  -H "apikey: YOUR_SUPABASE_ANON_KEY" \
  -H "Authorization: Bearer YOUR_SUPABASE_ANON_KEY" \
  -F "file=@audio.mp3" \
  -F "language=pt" \
  -F "diarization=true"
```

### 3. Testar pelo Frontend
1. Acesse o app: http://localhost:5175/
2. Ative o toggle "Identificar quem est√° falando"
3. Selecione um idioma
4. Fa√ßa upload de um arquivo de √°udio
5. Verifique se os speakers aparecem nos resultados

---

## üìà Recursos Adicionais da AssemblyAI

### Outros Recursos √öteis (Opcional)

```typescript
const transcriptConfig = {
  audio_url: upload_url,
  language_code: 'pt',

  // Diarization
  speaker_labels: true,
  speakers_expected: 2,  // Otimiza para 2 speakers

  // Outros recursos √∫teis:
  punctuate: true,          // Pontua√ß√£o autom√°tica
  format_text: true,        // Formata√ß√£o (n√∫meros, datas, etc.)
  filter_profanity: false,  // Censurar palavr√µes

  // Auto-detect de idioma (se language_code n√£o especificado)
  language_detection: true,

  // Resumo autom√°tico (pago)
  // summarization: true,
  // summary_model: 'informative',
  // summary_type: 'bullets'
}
```

---

## üí∞ Custos AssemblyAI

### Plano Gratuito
- **$0.00/m√™s**
- 100 minutos de transcri√ß√£o inclusos
- Speaker diarization inclu√≠do
- Timestamps inclu√≠dos
- Limite de 5 horas de √°udio

### Plano Pay-as-you-go
- **$0.00037/segundo** ($0.65/hora)
- Sem limite de minutos
- Todos os recursos inclu√≠dos
- Sem taxa mensal

**C√°lculo:**
- 1 entrevista de 30min = $0.325
- 100 entrevistas/m√™s (50h) = $32.50/m√™s

---

## ‚úÖ Checklist de Implementa√ß√£o

- [ ] Obter API Key da AssemblyAI
- [ ] Adicionar ASSEMBLYAI_API_KEY nas secrets da Edge Function
- [ ] Atualizar c√≥digo da Edge Function com diarization
- [ ] Fazer deploy da fun√ß√£o atualizada
- [ ] Testar com cURL
- [ ] Testar pelo frontend
- [ ] Verificar formato da resposta
- [ ] Validar que speakers aparecem corretamente
- [ ] Testar com diferentes idiomas
- [ ] Testar com √°udios de diferentes dura√ß√µes

---

## üîó Refer√™ncias

### Documenta√ß√£o Oficial
- [AssemblyAI Speaker Diarization](https://www.assemblyai.com/docs/Models/speaker_diarization)
- [AssemblyAI API Reference](https://www.assemblyai.com/docs/api-reference)
- [AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk)

### Tutoriais
- [Speaker Diarization Tutorial](https://www.assemblyai.com/blog/speaker-diarization-python)
- [Multichannel Audio Processing](https://www.assemblyai.com/blog/multichannel-speaker-diarization)

### GitHub Examples
- [AssemblyAI Speaker Diarization Example](https://github.com/AssemblyAI/speaker-diarization)

---

**Status:** üìù Guia completo - Pronto para implementa√ß√£o
**Data:** 2025-10-23
**Vers√£o:** 1.0.0
